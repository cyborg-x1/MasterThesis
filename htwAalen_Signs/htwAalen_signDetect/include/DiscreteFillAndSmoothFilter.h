#ifndef DISCRETEFILLANDSMOOTHFILTER_H_
#define DISCRETEFILLANDSMOOTHFILTER_H_

#include <set>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <iostream>
#include <iterator>
#include <math.h>


class DiscreteFillAndSmoothFilter
{
	//Include the autogenerated lookup tables

	static const int blub;

	typedef enum
	{
		SeekPlausibleValue,
		SeekStepOrZero,
		SeekNonZero,
		SeekBackwardOrForwardStep,
	}states_seek_t;


	cv::Mat cache;
	cv::Mat orig;
	cv::Mat dst;


	states_seek_t state_seek;

	short stored_value;


public:

	typedef cv::Vec<short, 1> Vec1shrt;

	DiscreteFillAndSmoothFilter();

	virtual ~DiscreteFillAndSmoothFilter();


	/**
	 * Reset the seek state machine
	 */
	void resetSeek();


	/**
	 * This returns the absolute discrete step difference
	 */
	short absoluteStepDifference(short value1, short value2);


	static void test()
	{
		std::cout<<blub<<std::endl;
	}


//	/**
//	 * This function converts a kinect depth image into steps
//	 *  @param [in] src The source image (CV_16UC1)
//	 *  @param [out] dst The destination image(CV_16UC1)
//	 */
//	static void convertKinectRawToSteps(const cv::Mat &src, cv::Mat &dst)
//	{
//		if(src.type() == CV_16UC1 && CV_16UC1 == dst.type())
//		{
//			int size_x=src.cols, size_y=src.rows;
//
//			for (int i = 0; i < (size_x*size_y); i++)
//			{
//				//Forward direction x -
//				int y_xfw=i/size_x, x_xfw=i-y_xfw*size_x;
//				short current=src.at<Vec1shrt>(y_xfw,x_xfw)[0];
//				if(current>=0 && current < kinect_step_to_depth_LUT_size)
//				{
//					if(kinect_depth_to_step_LUT[current]>=0)
//					{
//						dst.at<Vec1shrt>(y_xfw,x_xfw)[0]=kinect_depth_to_step_LUT[current];
//					}
//					else
//					{
//						dst.at<Vec1shrt>(y_xfw,x_xfw)[0]=0;
//						ROS_ERROR("KinectDepthToSteps: Unregistered Depth Value(%i:%i)!!!",current,kinect_depth_to_step_LUT[current]);
//					}
//				}
//				else
//				{
//					ROS_ERROR("KinectStepsToDepth: Depth too large!!!: %i", current);
//				}
//			}
//		}
//		else
//		{
//			ROS_ERROR("KinectStepsToDepth wrong type! Expects CV_16UC1");
//		}
//	}
//
//	/**
//	 * This function converts a step image into kinect depth image
//	 *  @param [in] src The source image (CV_16UC1)
//	 *  @param [out] dst The destination image(CV_16UC1)
//	 */
//	static void convertStepsToKinectRaw(const cv::Mat &src, cv::Mat &dst)
//	{
//		if(src.type() == CV_16UC1 && CV_16UC1 == dst.type())
//		{
//			int size_x=src.cols, size_y=src.rows;
//
//			for (int i = 0; i < (size_x*size_y); i++)
//			{
//				//Forward direction x -
//				int y_xfw=i/size_x, x_xfw=i-y_xfw*size_x;
//				short current=src.at<Vec1shrt>(y_xfw,x_xfw)[0];
//				if(current>=0 && current < kinect_depth_to_step_LUT_size)
//				{
//					dst.at<Vec1shrt>(y_xfw,x_xfw)[0]=kinect_step_to_depth_LUT[current];
//				}
//				else
//				{
//					ROS_ERROR("KinectStepsToDepth: Step value to large! %i",current);
//				}
//			}
//		}
//		else
//		{
//			ROS_ERROR("KinectStepsToDepth: Wrong type! Expects CV_16UC1");
//		}
//	}


};




#endif /* DISCRETEFILLANDSMOOTHFILTER_H_ */
