\chapter{SignRecognition}
\graphicspath{{./Software/img/}}
 
\section{Depth Image Processing}


\subsection{First Blur Filter}
Bluring the depth image sounds like an easy task but if a simple boxed filter is used all edges are smothed to surfaces
they do not belong to (see first picture in figure \vref{figure:blur}).
At first it was tried to do all the filtering and reset all blured pixels $P_n$ which are to far away from their 
original depth value by the following formula.

\[
 \forall P_n(x,y)  |   \left(\left|{P_n(x,y)-P(x,y)}\right|>{\frac{P(x,y)^2}{480000}}\right)\implies P_n(x,y)=P(x,y)
\]

The following listing shows the code of this first filter, which uses a box-filter and and a median-blur filter from
OpenCV. In the next step the previous formula is used to revert pixels as said above and then another blur filter 
is applied to remove possible noise resulting from that procedure (see figure \vref{figure:blur} for results).

{
\tiny
\newpage
\begin{lstlisting}
cv::Mat filter_in = src.clone();
cv::Mat filter=filter_in.clone();
cv::boxFilter(filter, filter, 3, cv::Size(7, 3), cv::Point(-1, -1), 1, 0);
cv::medianBlur(filter, filter, 3);

//Update non zero pixels
for (int y = 0; y < src.rows; y++)
{
	for (int x = 0; x < src.cols; x++)
	{
		short realValue = filter_in.at<Vec1shrt>(y, x)[0];
		short filteredValue = filter.at<Vec1shrt>(y, x)[0];
		short maxDifference = pow((float)realValue, 2) / (480000); //Maximal difference from the real value
		if (realValue>0)
		{
			if(abs(realValue - filteredValue) > maxDifference)
			{
				dst.at<Vec1shrt>(y, x)[0] = realValue;
			}
			else
			{
				dst.at<Vec1shrt>(y, x)[0] = filteredValue;
			}
		}
	}
}
cv::medianBlur(dst, dst, 3);

\end{lstlisting}
}


\pic{myFilter1.png}{Blur Filter (Boxed/Median/Reset Borders/Median)}{\label{figure:blur}}{0.6}{h}



\subsection{New Blur Filter}
After realizing that there are only 824 depth values available, it was decided to transform the depth picture
to the available depth steps. This step map now contains the number of each available depth like shown in figure \vref{figure:stepMap}.

\pic{stepmap.pdf}{Step Map Creation}{\label{figure:stepMap}}{1}{h}

With that new image it's now possible to determine if a pixel is a direct neighbor to another one. This is mostly the case,
when the value from the difference of the steps is smaller than or equal to one. A threshold of four is adequate to be sure 
to eliminate the noise created by the fractals which sometimes creates a step difference of 3 inside of a surface. 
So the neighborhood condition of one pixel $P$ to another pixel $P_i$ can be determind by the following formula.

\[
 \forall P_i(x_i,y_i)  |\mbox{   }
 \Big(\left|P_i(x_i,y_i)-P(x,y)\right|<4 \Big) \wedge  P_i(x_i,y_i) \neq 0 %\wedge  P(x,y) \neq 0 
\]
\[
 \implies P_i(x_i,y_i) \mbox{ is a close neighbor to } P(x,y)
\]

With this formula a neighborhood map is created which contains 8-bit values for each pixel, where each bit shows the neighborhood 
condition to one of the eight pixels around the current one (as seen in figure \vref{figure:neighborhoodmap}).

\pic{neighborhoodmap.pdf}{Neighborhood-Map Creation}{\label{figure:neighborhoodmap}}{1}{h}

This information helps to write a more performance saving, effective and edge saving bluring method which 
was named crossBlur because it blures each pixel with a specified number of it's neighbors on top, left, right and bottom.
The neighborhood condition is needed because it will stop adding pixels on each side if the next pixel in the direction 
is not a close neighbor to the current to preserve the edges. (see in figure \vref{figure:crossblur}).

\pic{crossBlur.pdf}{Cross Blur Working Principle}{\label{figure:crossblur}}{1}{h}


%TODO Result picture

After bluring the real world X and Y values of each point must be calculated. This is done with the camera information delivered 
from ROS. The code for this is copied from the rgbxyz-point cloud nodelet from ROS and a few things were changed.
All of the float values are multiplied by 100 and converted to integer. This is used to increase the accuracy while
calculating a integer value for x and y coordinates. The coordinates itself are stored as short. This was done to save
computational time by calculating the normals as integers instead of double format.
 
{
\tiny
\begin{lstlisting}

	xy=cv::Mat::zeros(src.rows,src.cols,CV_16UC2);

	image_geometry::PinholeCameraModel model;
	model.fromCameraInfo(info_msg);

	int center_x = model.cx()*100;					
	int center_y = model.cy()*100;					

	int constant_x = model.fx()*100;
	int constant_y = model.fy()*100;

	int size_x=src.cols, size_y=src.rows;

	int x,y;
	for (int i = 0; i < (size_x*size_y); i++)
	{
		y=i/size_x;
		x=i-y*size_x;

		if(x>0)
		{
			short depth=src.at<Vec1shrt>(y,x)[0];
			xy.at<Vec2shrt>(y,x)[0] = ((x*100 - center_x) * depth) / constant_x;
			xy.at<Vec2shrt>(y,x)[1] = ((y*100 - center_y) * depth) / constant_y;
		}
	}
\end{lstlisting}
}
% 			cv::Mat steps, neighbor_map, normals, xy,angles, angles_ok, filtered_bgr;
% 
% 
% 			//
% 			KinTo::convertKinectRawToSteps(imgPtrDepth->image,steps);  ///?
% 			KinTo::createRelationNeighbourhoodMap(steps,neighbor_map);
% 			KinTo::crossDepthBlur(imgPtrDepth->image,neighbor_map,imgPtrDepth->image,blur_depth);
% 			///
% 
% 			///
% 			KinTo::createXYMap(imgPtrDepth->image,info_msg,xy);
% 			KinTo::XYZrangeFilter(imgPtrDepth->image,xy,imgPtrDepth->image,x_min, x_max,  y_min, y_max, z_min, z_max);
% 			///
% 
% 			///
% 			KinTo::createNormalMap(imgPtrDepth->image,neighbor_map, xy,normals);
% 			KinTo::createAngleMap(normals,angles);
% 			///
% 
% 			///
% 			KinTo::crossAnglesBlur(angles,neighbor_map,angles,blur_angles);
% 			KinTo::anglesFilter(angles, angles_ok, x_angle_min, x_angle_max, y_angle_min, y_angle_max, z_angle_min, z_angle_max,true);
% 			///
% 
% 
% 			cv::blur(angles_ok,angles_ok,cv::Size(5,5),cv::Point(-1,-1),0);
% 			cv::threshold(angles_ok,angles_ok,1,255,0);




\pic{normals.pdf}{Normals Creation}{\label{figure:normals}}{1}{h}



\subsection{Range Filter}



\section{RGB Image Processing}


\section{Robot Control}
\subsection{ROS Transform}
\subsection{Navigation}
